{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Prediction System - Model Development\n",
    "\n",
    "**Student Name:** Oluwalase Soboyejo  \n",
    "**Matric Number:** 23CD034363  \n",
    "\n",
    "This notebook develops a machine learning model to predict whether a breast tumor is benign or malignant using the Breast Cancer Wisconsin (Diagnostic) dataset.\n",
    "\n",
    "**Note:** This system is strictly for educational purposes and must not be presented as a medical diagnostic tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn for ML\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Model persistence\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the Breast Cancer Wisconsin Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from sklearn\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data=breast_cancer.data, columns=breast_cancer.feature_names)\n",
    "\n",
    "# Add target variable\n",
    "df['diagnosis'] = breast_cancer.target\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "print(\"\\nFeature Names:\")\n",
    "print(breast_cancer.feature_names)\n",
    "print(\"\\nTarget Names:\", breast_cancer.target_names)  # 0 = malignant, 1 = benign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values per Column:\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\nTotal Missing Values:\", df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "print(\"Number of duplicate rows:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Feature Selection\n",
    "\n",
    "Selecting **5 input features** from the recommended list:\n",
    "1. radius_mean\n",
    "2. texture_mean\n",
    "3. perimeter_mean\n",
    "4. area_mean\n",
    "5. concavity_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the 5 selected features\n",
    "selected_features = [\n",
    "    'mean radius',\n",
    "    'mean texture',\n",
    "    'mean perimeter',\n",
    "    'mean area',\n",
    "    'mean concavity'\n",
    "]\n",
    "\n",
    "# Create feature matrix with selected features only\n",
    "X = df[selected_features].copy()\n",
    "\n",
    "# Target variable\n",
    "y = df['diagnosis'].copy()\n",
    "\n",
    "print(\"Selected Features:\")\n",
    "for i, feature in enumerate(selected_features, 1):\n",
    "    print(f\"  {i}. {feature}\")\n",
    "\n",
    "print(f\"\\nFeature Matrix Shape: {X.shape}\")\n",
    "print(f\"Target Vector Shape: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display selected features\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Encode Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The target is already encoded in sklearn's dataset:\n",
    "# 0 = Malignant, 1 = Benign\n",
    "print(\"Target Variable Distribution:\")\n",
    "print(y.value_counts())\n",
    "print(\"\\nMapping: 0 = Malignant, 1 = Benign\")\n",
    "\n",
    "# Visualize the distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.countplot(x=y, palette=['#FF6B6B', '#4ECDC4'])\n",
    "plt.title('Distribution of Diagnosis', fontsize=14)\n",
    "plt.xlabel('Diagnosis (0 = Malignant, 1 = Benign)', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks([0, 1], ['Malignant (0)', 'Benign (1)'])\n",
    "\n",
    "# Add count labels on bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{int(p.get_height())}', \n",
    "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
    "                ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap for selected features\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = X.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            fmt='.2f', linewidths=0.5)\n",
    "plt.title('Correlation Matrix of Selected Features', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for each feature by diagnosis\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, feature in enumerate(selected_features):\n",
    "    sns.boxplot(x=y, y=X[feature], ax=axes[idx], palette=['#FF6B6B', '#4ECDC4'])\n",
    "    axes[idx].set_title(f'{feature} by Diagnosis', fontsize=12)\n",
    "    axes[idx].set_xlabel('Diagnosis (0=Malignant, 1=Benign)')\n",
    "    axes[idx].set_ylabel(feature)\n",
    "\n",
    "# Remove the extra subplot\n",
    "axes[-1].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Split Data into Training and Testing Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data: 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training Set Size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing Set Size: {X_test.shape[0]} samples\")\n",
    "print(f\"\\nTraining Set Distribution:\")\n",
    "print(y_train.value_counts())\n",
    "print(f\"\\nTesting Set Distribution:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Feature Scaling (Mandatory for KNN)\n",
    "\n",
    "KNN is a distance-based algorithm, so feature scaling is essential to ensure all features contribute equally to the distance calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data and transform both sets\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=selected_features)\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=selected_features)\n",
    "\n",
    "print(\"Feature Scaling Applied Successfully!\")\n",
    "print(\"\\nScaled Training Data Statistics:\")\n",
    "print(X_train_scaled_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Implementation - K-Nearest Neighbors (KNN)\n",
    "\n",
    "KNN is a simple, yet powerful classification algorithm that classifies new data points based on the majority class of their k nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Find Optimal K Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different values of k to find the optimal one\n",
    "k_range = range(1, 31)\n",
    "accuracy_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train_scaled, y_train)\n",
    "    y_pred = knn.predict(X_test_scaled)\n",
    "    accuracy_scores.append(accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Find the best k\n",
    "best_k = k_range[np.argmax(accuracy_scores)]\n",
    "best_accuracy = max(accuracy_scores)\n",
    "\n",
    "print(f\"Best K value: {best_k}\")\n",
    "print(f\"Best Accuracy: {best_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize accuracy vs k values\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(k_range, accuracy_scores, 'b-', marker='o', markersize=5)\n",
    "plt.axvline(x=best_k, color='r', linestyle='--', label=f'Best K = {best_k}')\n",
    "plt.xlabel('Number of Neighbors (K)', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('KNN Accuracy vs Number of Neighbors', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Train the Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the KNN model with optimal k\n",
    "knn_model = KNeighborsClassifier(n_neighbors=best_k, metric='euclidean')\n",
    "knn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"KNN Model trained successfully with K = {best_k}\")\n",
    "print(f\"\\nModel Parameters:\")\n",
    "print(knn_model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "y_pred = knn_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"MODEL EVALUATION METRICS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nAccuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed classification report\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(\"=\" * 50)\n",
    "print(classification_report(y_test, y_pred, target_names=['Malignant', 'Benign']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Malignant', 'Benign'],\n",
    "            yticklabels=['Malignant', 'Benign'])\n",
    "plt.title('Confusion Matrix', fontsize=14)\n",
    "plt.xlabel('Predicted Label', fontsize=12)\n",
    "plt.ylabel('True Label', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTrue Negatives (TN): {cm[0][0]} - Correctly predicted Malignant\")\n",
    "print(f\"False Positives (FP): {cm[0][1]} - Malignant predicted as Benign\")\n",
    "print(f\"False Negatives (FN): {cm[1][0]} - Benign predicted as Malignant\")\n",
    "print(f\"True Positives (TP): {cm[1][1]} - Correctly predicted Benign\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary containing all necessary components\n",
    "model_components = {\n",
    "    'model': knn_model,\n",
    "    'scaler': scaler,\n",
    "    'feature_names': selected_features,\n",
    "    'best_k': best_k\n",
    "}\n",
    "\n",
    "# Save using joblib\n",
    "model_path = 'breast_cancer_model.pkl'\n",
    "joblib.dump(model_components, model_path)\n",
    "\n",
    "print(f\"Model saved successfully to: {model_path}\")\n",
    "print(f\"File size: {os.path.getsize(model_path) / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Demonstrate Model Loading and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_components = joblib.load(model_path)\n",
    "\n",
    "# Extract components\n",
    "loaded_model = loaded_components['model']\n",
    "loaded_scaler = loaded_components['scaler']\n",
    "loaded_features = loaded_components['feature_names']\n",
    "\n",
    "print(\"Model loaded successfully!\")\n",
    "print(f\"\\nFeatures expected: {loaded_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction with sample data\n",
    "# Sample 1: Typical Malignant tumor characteristics (larger values)\n",
    "sample_malignant = np.array([[17.99, 10.38, 122.8, 1001, 0.3001]])\n",
    "\n",
    "# Sample 2: Typical Benign tumor characteristics (smaller values)\n",
    "sample_benign = np.array([[12.46, 24.04, 83.97, 475.9, 0.0484]])\n",
    "\n",
    "# Scale the samples\n",
    "sample_malignant_scaled = loaded_scaler.transform(sample_malignant)\n",
    "sample_benign_scaled = loaded_scaler.transform(sample_benign)\n",
    "\n",
    "# Make predictions\n",
    "pred_malignant = loaded_model.predict(sample_malignant_scaled)\n",
    "pred_benign = loaded_model.predict(sample_benign_scaled)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"DEMONSTRATION: Prediction without Retraining\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n--- Sample 1 (Expected: Malignant) ---\")\n",
    "print(f\"Input Features:\")\n",
    "for feature, value in zip(loaded_features, sample_malignant[0]):\n",
    "    print(f\"  {feature}: {value}\")\n",
    "print(f\"Prediction: {'Malignant' if pred_malignant[0] == 0 else 'Benign'}\")\n",
    "\n",
    "print(\"\\n--- Sample 2 (Expected: Benign) ---\")\n",
    "print(f\"Input Features:\")\n",
    "for feature, value in zip(loaded_features, sample_benign[0]):\n",
    "    print(f\"  {feature}: {value}\")\n",
    "print(f\"Prediction: {'Malignant' if pred_benign[0] == 0 else 'Benign'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify model consistency - predictions on test set should be the same\n",
    "loaded_predictions = loaded_model.predict(X_test_scaled)\n",
    "original_predictions = y_pred\n",
    "\n",
    "predictions_match = np.array_equal(loaded_predictions, original_predictions)\n",
    "print(f\"Loaded model predictions match original: {predictions_match}\")\n",
    "print(f\"Loaded model accuracy: {accuracy_score(y_test, loaded_predictions):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "### Model Development Summary\n",
    "\n",
    "| Aspect | Details |\n",
    "|--------|----------|\n",
    "| **Dataset** | Breast Cancer Wisconsin (Diagnostic) |\n",
    "| **Total Samples** | 569 |\n",
    "| **Algorithm** | K-Nearest Neighbors (KNN) |\n",
    "| **Selected Features** | radius_mean, texture_mean, perimeter_mean, area_mean, concavity_mean |\n",
    "| **Optimal K Value** | Determined through cross-validation |\n",
    "| **Feature Scaling** | StandardScaler |\n",
    "| **Model Persistence** | Joblib |\n",
    "\n",
    "### Performance Metrics\n",
    "\n",
    "The model achieves good performance on the test set with metrics reported above.\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "The saved model (`breast_cancer_model.pkl`) will be used in the Flask web application (`app.py`) to provide predictions through a user-friendly interface.\n",
    "\n",
    "---\n",
    "\n",
    "**Disclaimer:** This system is strictly for educational purposes and must not be presented as a medical diagnostic tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL DEVELOPMENT COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nSaved Model: {model_path}\")\n",
    "print(f\"Algorithm: K-Nearest Neighbors (K={best_k})\")\n",
    "print(f\"Features: {selected_features}\")\n",
    "print(f\"Model Persistence: Joblib\")\n",
    "print(\"\\nReady for deployment with Flask web application!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
